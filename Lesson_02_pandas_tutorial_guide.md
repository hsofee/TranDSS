# ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏≠‡∏ô Pandas
## ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ

---

## üìä ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç
1. [‡∏ö‡∏ó‡∏ô‡∏≥ Pandas](#‡∏ö‡∏ó‡∏ô‡∏≥-pandas)
2. [‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£ Import](#‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£-import)
3. [Series ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô](#series-‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô)
4. [DataFrame ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô](#dataframe-‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô)
5. [‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•](#‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
6. [Data Selection ‡πÅ‡∏•‡∏∞ Filtering](#data-selection-‡πÅ‡∏•‡∏∞-filtering)
7. [‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î](#‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î)
8. [‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥](#‡πÇ‡∏Ñ‡∏£‡∏á‡∏á‡∏≤‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥)

---

## ‡∏ö‡∏ó‡∏ô‡∏≥ Pandas

### Pandas ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?
**Pandas** (Python Data Analysis Library) ‡πÄ‡∏õ‡πá‡∏ô library ‡∏ó‡∏µ‡πà‡∏ó‡∏£‡∏á‡∏û‡∏•‡∏±‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Python ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏£‡πá‡∏ß‡πÅ‡∏•‡∏∞‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö structured

### ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Pandas?

#### ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

```python
# ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ Pandas - ‡∏¢‡∏∏‡πà‡∏á‡∏¢‡∏≤‡∏Å
data = [
    ['Alice', 25, 50000],
    ['Bob', 30, 60000],
    ['Charlie', 35, 70000]
]

# ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
total_salary = sum(row[2] for row in data)
avg_salary = total_salary / len(data)

# ‡πÉ‡∏ä‡πâ Pandas - ‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
import pandas as pd
df = pd.DataFrame(data, columns=['Name', 'Age', 'Salary'])
avg_salary = df['Salary'].mean()
```

### ‡∏Ç‡πâ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á Pandas
- **Easy Data Manipulation**: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢
- **Multiple File Formats**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏≤‡∏¢‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö (CSV, Excel, JSON, SQL)
- **Missing Data Handling**: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏î‡∏µ
- **Data Alignment**: ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
- **Flexible Grouping**: ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢
- **Integration**: ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏£‡πà‡∏ß‡∏°‡∏Å‡∏±‡∏ö NumPy, Matplotlib ‡πÑ‡∏î‡πâ‡∏î‡∏µ

### ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
- ‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏Å‡∏≤‡∏£ Data Science ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 95%
- ‡∏°‡∏µ‡∏Å‡∏≤‡∏£ download ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 50 ‡∏•‡πâ‡∏≤‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
- Essential tool ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Data Scientists ‡∏ó‡∏±‡πà‡∏ß‡πÇ‡∏•‡∏Å

---

## ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£ Import

### ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á
```bash
# ‡∏ú‡πà‡∏≤‡∏ô pip
pip install pandas

# ‡∏ú‡πà‡∏≤‡∏ô conda
conda install pandas

# ‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ö dependencies ‡∏≠‡∏∑‡πà‡∏ô‡πÜ
pip install pandas numpy matplotlib seaborn

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö version
python -c "import pandas as pd; print(pd.__version__)"
```

### ‡∏Å‡∏≤‡∏£ Import
```python
# Standard import
import pandas as pd
import numpy as np

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö version
print(f"Pandas version: {pd.__version__}")

# Import ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
from pandas import DataFrame, Series, read_csv

# ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ display options
pd.set_option('display.max_rows', 100)
pd.set_option('display.max_columns', 20)
pd.set_option('display.width', 1000)
```

### ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
```python
# ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏°
pd.set_option('display.float_format', '{:.2f}'.format)

# ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà
pd.set_option('display.max_colwidth', 50)

# ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤
pd.reset_option('all')

# ‡∏î‡∏π‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
print(pd.describe_option())
```

---

## Series ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô

### Series ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?
**Series** ‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 1 ‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏ô‡∏¥‡∏î‡πÉ‡∏î‡∏Å‡πá‡πÑ‡∏î‡πâ (integers, strings, floats, Python objects) ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ö labels (index)

### ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Series

```python
import pandas as pd
import numpy as np

# ‡∏à‡∏≤‡∏Å Python list
s1 = pd.Series([1, 3, 5, np.nan, 6, 8])
print(s1)

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î index ‡πÄ‡∏≠‡∏á
s2 = pd.Series([1, 3, 5, 6], index=['a', 'b', 'c', 'd'])
print(s2)

# ‡∏à‡∏≤‡∏Å dictionary
data_dict = {'A': 1, 'B': 2, 'C': 3, 'D': 4}
s3 = pd.Series(data_dict)
print(s3)

# ‡∏à‡∏≤‡∏Å NumPy array
arr = np.array([1, 2, 3, 4, 5])
s4 = pd.Series(arr, index=['x', 'y', 'z', 'w', 'v'])
print(s4)

# Series ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
s5 = pd.Series(5, index=[0, 1, 2, 3])
print(s5)
```

### ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á Series
```python
s = pd.Series([1, 3, 5, np.nan, 6, 8], index=['a', 'b', 'c', 'd', 'e', 'f'])

# ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
print(f"Values: {s.values}")          # NumPy array
print(f"Index: {s.index}")            # Index object
print(f"Data type: {s.dtype}")        # ‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
print(f"Shape: {s.shape}")            # ‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á
print(f"Size: {s.size}")              # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô elements
print(f"Name: {s.name}")              # ‡∏ä‡∏∑‡πà‡∏≠ Series

# ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Series ‡πÅ‡∏•‡∏∞ index
s.name = 'My Series'
s.index.name = 'Labels'
print(s)
```

### ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Series
```python
s = pd.Series([10, 20, 30, 40, 50], index=['a', 'b', 'c', 'd', 'e'])

# ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏î‡πâ‡∏ß‡∏¢ label
print(s['b'])                    # 20
print(s[['a', 'c', 'e']])        # Multiple labels

# ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏î‡πâ‡∏ß‡∏¢ position
print(s[1])                      # 20
print(s[0:3])                    # Slicing

# Boolean indexing
print(s[s > 25])                 # ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 25

# ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö
print('b' in s)                  # True
print(s.get('f', 'Not found'))   # Get with default value
```

### ‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö Series
```python
s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])
s2 = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])

# Arithmetic operations
print(s1 + s2)                   # Element-wise addition
print(s1 * 2)                    # Scalar multiplication
print(s1 ** 2)                   # Power

# Statistical operations
print(s1.sum())                  # ‡∏ú‡∏•‡∏£‡∏ß‡∏°
print(s1.mean())                 # ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
print(s1.std())                  # ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ö‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
print(s1.describe())             # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°

# String operations (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Series ‡∏ó‡∏µ‡πà‡∏°‡∏µ string)
s_str = pd.Series(['apple', 'banana', 'cherry'])
print(s_str.str.upper())         # ‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÉ‡∏´‡∏ç‡πà
print(s_str.str.len())           # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß string
print(s_str.str.contains('a'))   # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ 'a'
```

---

## DataFrame ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô

### DataFrame ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?
**DataFrame** ‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 2 ‡∏°‡∏¥‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô table ‡πÉ‡∏ô SQL ‡∏´‡∏£‡∏∑‡∏≠ spreadsheet ‡πÉ‡∏ô Excel ‡πÇ‡∏î‡∏¢‡∏°‡∏µ labeled axes (rows ‡πÅ‡∏•‡∏∞ columns)

### ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame

```python
# ‡∏à‡∏≤‡∏Å dictionary
data = {
    'Name': ['Alice', 'Bob', 'Charlie', 'Diana'],
    'Age': [25, 30, 35, 28],
    'City': ['New York', 'London', 'Tokyo', 'Paris'],
    'Salary': [50000, 60000, 70000, 55000]
}
df = pd.DataFrame(data)
print(df)

# ‡∏à‡∏≤‡∏Å list of dictionaries
data_list = [
    {'Name': 'Alice', 'Age': 25, 'City': 'New York'},
    {'Name': 'Bob', 'Age': 30, 'City': 'London'},
    {'Name': 'Charlie', 'Age': 35, 'City': 'Tokyo'}
]
df2 = pd.DataFrame(data_list)
print(df2)

# ‡∏à‡∏≤‡∏Å NumPy array
arr = np.random.randn(4, 3)
df3 = pd.DataFrame(arr, 
                   columns=['A', 'B', 'C'],
                   index=['Row1', 'Row2', 'Row3', 'Row4'])
print(df3)

# ‡∏à‡∏≤‡∏Å Series
s1 = pd.Series([1, 2, 3], name='Col1')
s2 = pd.Series([4, 5, 6], name='Col2')
df4 = pd.DataFrame({'Col1': s1, 'Col2': s2})
print(df4)
```

### ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á DataFrame
```python
df = pd.DataFrame({
    'A': [1, 2, 3, 4],
    'B': [5.0, 6.0, 7.0, 8.0],
    'C': ['foo', 'bar', 'baz', 'qux'],
    'D': [True, False, True, False]
})

# ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
print(f"Shape: {df.shape}")              # (rows, columns)
print(f"Size: {df.size}")                # total elements
print(f"Columns: {df.columns}")          # column names
print(f"Index: {df.index}")              # row indices
print(f"Data types:\n{df.dtypes}")       # data types
print(f"Memory usage:\n{df.memory_usage()}")

# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
print(df.head())                         # 5 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å
print(df.tail(3))                        # 3 ‡πÅ‡∏ñ‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
print(df.info())                         # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°
print(df.describe())                     # ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö numeric columns
```

### ‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô DataFrame

#### ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Columns
```python
df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie'],
    'Age': [25, 30, 35],
    'Salary': [50000, 60000, 70000]
})

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å 1 column (‡πÑ‡∏î‡πâ Series)
print(df['Name'])

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏•‡∏≤‡∏¢ columns (‡πÑ‡∏î‡πâ DataFrame)
print(df[['Name', 'Salary']])

# ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡∏î‡πâ‡∏ß‡∏¢ attribute (‡∏ñ‡πâ‡∏≤‡∏ä‡∏∑‡πà‡∏≠ column ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á)
print(df.Name)
```

#### ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Rows
```python
# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢ position
print(df.iloc[0])              # ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å (Series)
print(df.iloc[0:2])            # ‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà 0-1 (DataFrame)

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏î‡πâ‡∏ß‡∏¢ label
df_indexed = df.set_index('Name')
print(df_indexed.loc['Alice'])  # ‡πÅ‡∏ñ‡∏ß‡∏Ç‡∏≠‡∏á Alice

# Boolean indexing
print(df[df['Age'] > 30])       # ‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏¢‡∏∏‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 30
print(df[df['Name'].isin(['Alice', 'Charlie'])])  # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞
```

#### ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Cells ‡πÄ‡∏â‡∏û‡∏≤‡∏∞
```python
# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å cell ‡πÄ‡∏â‡∏û‡∏≤‡∏∞
print(df.iloc[0, 1])           # ‡πÅ‡∏ñ‡∏ß 0, column 1
print(df.loc[0, 'Age'])        # ‡πÅ‡∏ñ‡∏ß 0, column 'Age'

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ä‡πà‡∏ß‡∏á
print(df.iloc[0:2, 1:3])       # ‡πÅ‡∏ñ‡∏ß 0-1, column 1-2
print(df.loc[0:1, 'Age':'Salary'])  # ‡πÅ‡∏ñ‡∏ß 0-1, column Age-Salary
```

---

## ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

### ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ

#### CSV Files
```python
# ‡∏≠‡πà‡∏≤‡∏ô CSV ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
df = pd.read_csv('data.csv')

# ‡∏û‡∏£‡πâ‡∏≠‡∏° parameters ‡∏ï‡πà‡∏≤‡∏á‡πÜ
df = pd.read_csv(
    'data.csv',
    sep=',',                    # ‡∏ï‡∏±‡∏ß‡πÅ‡∏ö‡πà‡∏á
    header=0,                   # ‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô header
    index_col=0,                # column ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô index
    usecols=['Name', 'Age'],    # column ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    dtype={'Age': int},         # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    parse_dates=['Date'],       # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô datetime
    na_values=['N/A', 'NULL']   # ‡∏Ñ‡πà‡∏≤ missing
)

# ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å URL
url = 'https://example.com/data.csv'
df = pd.read_csv(url)

# ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ö‡∏≤‡∏á‡πÅ‡∏ñ‡∏ß
df = pd.read_csv('data.csv', nrows=100)  # ‡∏≠‡πà‡∏≤‡∏ô 100 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å
df = pd.read_csv('data.csv', skiprows=10)  # ‡∏Ç‡πâ‡∏≤‡∏° 10 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å
```

#### Excel Files
```python
# ‡∏≠‡πà‡∏≤‡∏ô Excel
df = pd.read_excel('data.xlsx')

# ‡∏≠‡πà‡∏≤‡∏ô sheet ‡πÄ‡∏â‡∏û‡∏≤‡∏∞
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')

# ‡∏≠‡πà‡∏≤‡∏ô‡∏´‡∏•‡∏≤‡∏¢ sheets
dfs = pd.read_excel('data.xlsx', sheet_name=None)  # dictionary ‡∏Ç‡∏≠‡∏á DataFrames

# ‡∏û‡∏£‡πâ‡∏≠‡∏° parameters
df = pd.read_excel(
    'data.xlsx',
    sheet_name='Data',
    header=0,
    index_col=0,
    usecols='A:D',             # columns A ‡∏ñ‡∏∂‡∏á D
    skiprows=2                 # ‡∏Ç‡πâ‡∏≤‡∏° 2 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å
)
```

#### JSON Files
```python
# ‡∏≠‡πà‡∏≤‡∏ô JSON
df = pd.read_json('data.json')

# JSON ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á‡πÜ
df = pd.read_json('data.json', orient='records')  # list of objects
df = pd.read_json('data.json', orient='index')    # object of objects
df = pd.read_json('data.json', lines=True)        # JSON Lines format
```

#### SQL Database
```python
import sqlite3

# ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
conn = sqlite3.connect('database.db')

# ‡∏≠‡πà‡∏≤‡∏ô‡∏à‡∏≤‡∏Å SQL query
df = pd.read_sql_query('SELECT * FROM table_name', conn)

# ‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á table
df = pd.read_sql_table('table_name', conn)

# ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠
conn.close()
```

### ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

```python
df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie'],
    'Age': [25, 30, 35],
    'Salary': [50000, 60000, 70000]
})

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô CSV
df.to_csv('output.csv', index=False)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô Excel
df.to_excel('output.xlsx', sheet_name='Data', index=False)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô JSON
df.to_json('output.json', orient='records', indent=2)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
conn = sqlite3.connect('database.db')
df.to_sql('table_name', conn, if_exists='replace', index=False)
conn.close()

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô
df[['Name', 'Age']].to_csv('partial_data.csv', index=False)
```

---

## Data Selection ‡πÅ‡∏•‡∏∞ Filtering

### ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•

#### Basic Selection
```python
df = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],
    'Age': [25, 30, 35, 28, 32],
    'City': ['NY', 'London', 'Tokyo', 'Paris', 'Berlin'],
    'Salary': [50000, 60000, 70000, 55000, 65000],
    'Department': ['IT', 'HR', 'IT', 'Finance', 'IT']
})

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å columns
single_col = df['Name']                    # Series
multi_cols = df[['Name', 'Age', 'Salary']] # DataFrame

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å rows ‡∏î‡πâ‡∏ß‡∏¢ conditions
high_salary = df[df['Salary'] > 60000]
it_employees = df[df['Department'] == 'IT']
young_high_earners = df[(df['Age'] < 30) & (df['Salary'] > 50000)]
```

#### iloc ‡πÅ‡∏•‡∏∞ loc
```python
# iloc - position-based selection
print(df.iloc[0])              # ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å
print(df.iloc[0:3])            # ‡πÅ‡∏ñ‡∏ß 0-2
print(df.iloc[:, 1:3])         # columns 1-2 ‡∏ó‡∏∏‡∏Å‡πÅ‡∏ñ‡∏ß
print(df.iloc[0:2, 1:3])       # ‡πÅ‡∏ñ‡∏ß 0-1, columns 1-2

# loc - label-based selection
df_with_index = df.set_index('Name')
print(df_with_index.loc['Alice'])           # ‡πÅ‡∏ñ‡∏ß‡∏Ç‡∏≠‡∏á Alice
print(df_with_index.loc['Alice':'Charlie']) # ‡πÅ‡∏ñ‡∏ß Alice ‡∏ñ‡∏∂‡∏á Charlie
print(df_with_index.loc[:, 'Age':'Salary']) # columns Age ‡∏ñ‡∏∂‡∏á Salary
```

#### Query Method
```python
# ‡πÉ‡∏ä‡πâ query ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö filtering ‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô
result1 = df.query('Age > 30')
result2 = df.query('Age > 30 and Salary < 70000')
result3 = df.query('Department == "IT"')
result4 = df.query('City in ["NY", "Tokyo"]')

# ‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ external
min_age = 30
result5 = df.query('Age > @min_age')
```

### Advanced Filtering

#### ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ isin()
```python
# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
cities_of_interest = ['NY', 'Tokyo', 'Paris']
filtered = df[df['City'].isin(cities_of_interest)]

# ‡∏ï‡∏£‡∏á‡∏Ç‡πâ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á isin
not_in_cities = df[~df['City'].isin(cities_of_interest)]
```

#### String Filtering
```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
df_str = pd.DataFrame({
    'Name': ['Alice Johnson', 'Bob Smith', 'Charlie Brown', 'Diana Wilson'],
    'Email': ['alice@gmail.com', 'bob@yahoo.com', 'charlie@gmail.com', 'diana@outlook.com']
})

# String methods
gmail_users = df_str[df_str['Email'].str.contains('gmail')]
starts_with_a = df_str[df_str['Name'].str.startswith('A')]
ends_with_son = df_str[df_str['Name'].str.endswith('son')]

# Case-insensitive search
contains_alice = df_str[df_str['Name'].str.contains('alice', case=False)]

# Regular expressions
pattern_match = df_str[df_str['Email'].str.match(r'\w+@gmail\.com')]
```

#### ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Missing Values ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Filter
```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ missing values
df_missing = pd.DataFrame({
    'A': [1, 2, np.nan, 4, 5],
    'B': [np.nan, 2, 3, 4, np.nan],
    'C': [1, 2, 3, 4, 5]
})

# Filter ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ missing values
no_missing = df_missing[df_missing['A'].notna()]

# Filter ‡∏ó‡∏µ‡πà‡∏°‡∏µ missing values
has_missing = df_missing[df_missing['A'].isna()]

# Filter ‡∏´‡∏•‡∏≤‡∏¢ columns
complete_rows = df_missing.dropna()  # ‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ missing values
any_missing = df_missing[df_missing.isna().any(axis=1)]  # ‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ missing values
```


## ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î

### ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 1: Series ‡πÅ‡∏•‡∏∞ DataFrame ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (15 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)

#### ‡∏Ç‡πâ‡∏≠ 1.1 (5 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
‡∏™‡∏£‡πâ‡∏≤‡∏á Series ‡πÅ‡∏•‡∏∞ DataFrame ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î:

```python
# TODO: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡∏£‡πâ‡∏≤‡∏á
# a) Series ‡∏ó‡∏µ‡πà‡∏°‡∏µ index ‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡πÅ‡∏•‡∏∞ values ‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ô‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
# b) DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô 5 ‡∏Ñ‡∏ô ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢:
#    - ‡∏ä‡∏∑‡πà‡∏≠ (Name)
#    - ‡∏≠‡∏≤‡∏¢‡∏∏ (Age) 
#    - ‡πÄ‡∏Å‡∏£‡∏î (Grade)
#    - ‡πÄ‡∏°‡∏∑‡∏≠‡∏á (City)
# c) ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á DataFrame (shape, dtypes, info)
```

**‡πÄ‡∏â‡∏•‡∏¢:**
```python
# a) Series ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
months_days = pd.Series(
    [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31],
    index=['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
           'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],
    name='Days_in_Month'
)

# b) DataFrame ‡∏ô‡∏±‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ô
students = pd.DataFrame({
    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],
    'Age': [20, 21, 19, 22, 20],
    'Grade': ['A', 'B', 'A', 'C', 'B'],
    'City': ['Bangkok', 'Chiang Mai', 'Phuket', 'Bangkok', 'Pattaya']
})

# c) ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
print(f"Shape: {students.shape}")
print(f"Data types:\n{students.dtypes}")
print(f"Info:\n{students.info()}")
```

#### ‡∏Ç‡πâ‡∏≠ 1.2 (5 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ ‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ selection ‡πÅ‡∏•‡∏∞ filtering:

```python
sales_data = pd.DataFrame({
    'Date': pd.date_range('2023-01-01', periods=50, freq='D'),
    'Product': np.random.choice(['A', 'B', 'C'], 50),
    'Sales': np.random.randint(100, 1000, 50),
    'Region': np.random.choice(['North', 'South', 'East', 'West'], 50)
})

# TODO: ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î
# a) ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤ 'A' ‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 500
# b) ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ
# c) ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 10 ‡∏ß‡∏±‡∏ô‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°
# d) ‡∏™‡∏£‡πâ‡∏≤‡∏á column ‡πÉ‡∏´‡∏°‡πà‡∏ä‡∏∑‡πà‡∏≠ 'Sales_Category' ‡∏ó‡∏µ‡πà‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô 'High' (>700), 'Medium' (400-700), 'Low' (<400)
```

#### ‡∏Ç‡πâ‡∏≠ 1.3 (5 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå DataFrame:

```python
def analyze_dataframe(df, numeric_cols=None):
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå DataFrame ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•
    
    Parameters:
    df: DataFrame ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    numeric_cols: list ‡∏Ç‡∏≠‡∏á numeric columns (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ó‡∏∏‡∏Å numeric columns)
    
    Returns:
    dict ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•:
    - shape: ‡∏£‡∏π‡∏õ‡∏£‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á DataFrame
    - missing_values: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô missing values ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ column
    - numeric_summary: ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á numeric columns
    - categorical_summary: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô unique values ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ categorical column
    """
    # TODO: implement function
    pass

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô
test_data = pd.DataFrame({
    'A': [1, 2, np.nan, 4, 5],
    'B': ['x', 'y', 'x', 'z', 'y'],
    'C': [10.5, 20.3, 30.1, np.nan, 50.2]
})

result = analyze_dataframe(test_data)
```

### ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 2: Data Cleaning (20 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)

#### ‡∏Ç‡πâ‡∏≠ 2.1 (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ ‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î:

```python
messy_data = pd.DataFrame({
    'Name': ['  Alice  ', 'BOB', 'charlie brown', '  DIANA', 'Eve'],
    'Age': [25, 'thirty', 35, np.nan, '28'],
    'Email': ['alice@gmail.com', 'BOB@YAHOO.COM', 'charlie@gmail.com', 'diana@', 'eve@outlook.com'],
    'Salary': ['50,000', '60000', 'sixty thousand', '55,000', np.nan],
    'Phone': ['123-456-7890', '(234) 567-8901', '345.678.9012', '456 789 0123', '567-890-1234'],
    'Date_Joined': ['2023-01-01', '2023/02/15', '01-03-2023', '2023.04.10', '2023-05-20']
})

# TODO: ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# 1. ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î Name column (trim, proper case)
# 2. ‡πÅ‡∏õ‡∏•‡∏á Age ‡πÄ‡∏õ‡πá‡∏ô numeric (handle text values)
# 3. ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î Email (lowercase, validate format)
# 4. ‡πÅ‡∏õ‡∏•‡∏á Salary ‡πÄ‡∏õ‡πá‡∏ô numeric (remove commas, handle text)
# 5. ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Phone ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô xxx-xxx-xxxx
# 6. ‡πÅ‡∏õ‡∏•‡∏á Date_Joined ‡πÄ‡∏õ‡πá‡∏ô datetime
# 7. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ missing values ‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°
```

#### ‡∏Ç‡πâ‡∏≠ 2.2 (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô data cleaning pipeline:

```python
def clean_employee_data(df):
    """
    Data cleaning pipeline ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô
    
    Parameters:
    df: DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ columns: Name, Age, Email, Salary, Phone, Date_Joined
    
    Returns:
    DataFrame ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß
    
    Cleaning steps:
    1. Remove leading/trailing spaces from string columns
    2. Convert text ages to numeric
    3. Standardize email format (lowercase)
    4. Convert salary strings to numeric
    5. Standardize phone format
    6. Convert date strings to datetime
    7. Handle missing values appropriately
    8. Remove duplicates
    9. Add validation flags for invalid data
    """
    # TODO: implement cleaning pipeline
    pass

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö pipeline
cleaned_data = clean_employee_data(messy_data)
print("Cleaned data:")
print(cleaned_data)
print(f"\nData types after cleaning:\n{cleaned_data.dtypes}")
```

### ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 3: Groupby ‡πÅ‡∏•‡∏∞ Aggregation (20 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)

#### ‡∏Ç‡πâ‡∏≠ 3.1 (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ:

```python
sales_analysis = pd.DataFrame({
    'Date': pd.date_range('2023-01-01', periods=365, freq='D'),
    'Product': np.random.choice(['Laptop', 'Phone', 'Tablet', 'Watch'], 365),
    'Category': np.random.choice(['Electronics', 'Accessories'], 365),
    'Region': np.random.choice(['North', 'South', 'East', 'West'], 365),
    'Salesperson': np.random.choice(['Alice', 'Bob', 'Charlie', 'Diana'], 365),
    'Units_Sold': np.random.randint(1, 20, 365),
    'Unit_Price': np.random.randint(100, 2000, 365)
})
sales_analysis['Total_Sales'] = sales_analysis['Units_Sold'] * sales_analysis['Unit_Price']

# TODO: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
# 1. ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
# 2. Top 3 salesperson ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
# 3. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
# 4. ‡∏ú‡∏•‡∏¥‡∏ï‡∏†‡∏±‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏¢‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ï‡∏£‡∏°‡∏≤‡∏™
# 5. Seasonal analysis: ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô
```

#### ‡∏Ç‡πâ‡∏≠ 3.2 (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
‡∏™‡∏£‡πâ‡∏≤‡∏á advanced aggregation functions:

```python
def sales_metrics(group):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì metrics ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢
    
    Returns:
    Series ‡∏ó‡∏µ‡πà‡∏°‡∏µ:
    - total_sales: ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏£‡∏ß‡∏°
    - avg_sales: ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
    - sales_std: ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡πÄ‡∏ö‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
    - max_sales: ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
    - min_sales: ‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î
    - sales_range: ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î
    - coefficient_of_variation: CV
    """
    # TODO: implement metrics calculation
    pass

def product_performance_analysis(df, date_col, product_col, sales_col):
    """
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå performance ‡∏Ç‡∏≠‡∏á‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
    
    Parameters:
    df: DataFrame
    date_col: ‡∏ä‡∏∑‡πà‡∏≠ column ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô date
    product_col: ‡∏ä‡∏∑‡πà‡∏≠ column ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô product
    sales_col: ‡∏ä‡∏∑‡πà‡∏≠ column ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô sales
    
    Returns:
    DataFrame ‡∏ó‡∏µ‡πà‡∏°‡∏µ analysis results ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤
    """
    # TODO: implement product analysis
    pass

# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô
metrics_result = sales_analysis.groupby('Product').apply(sales_metrics)
performance_result = product_performance_analysis(sales_analysis, 'Date', 'Product', 'Total_Sales')
```

### ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 4: Time Series ‡πÅ‡∏•‡∏∞ Merging (25 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)

#### ‡∏Ç‡πâ‡∏≠ 4.1 (15 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå time series data:

```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• stock prices
stock_data = pd.DataFrame({
    'Date': pd.date_range('2023-01-01', periods=252, freq='B'),  # Business days
    'AAPL': np.random.randn(252).cumsum() + 150,
    'GOOGL': np.random.randn(252).cumsum() + 2500,
    'MSFT': np.random.randn(252).cumsum() + 250,
    'TSLA': np.random.randn(252).cumsum() + 200
}).set_index('Date')

# TODO: Time series analysis
# 1. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì daily returns ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏∏‡πâ‡∏ô
# 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì 20-day ‡πÅ‡∏•‡∏∞ 50-day moving averages
# 3. ‡∏´‡∏≤ correlation matrix ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏∏‡πâ‡∏ô‡∏ï‡πà‡∏≤‡∏á‡πÜ
# 4. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì monthly returns ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ resampling
# 5. ‡∏´‡∏≤‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ volatility ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (‡πÉ‡∏ä‡πâ rolling standard deviation)
# 6. ‡∏™‡∏£‡πâ‡∏≤‡∏á simple trading signal: ‡∏ã‡∏∑‡πâ‡∏≠‡πÄ‡∏°‡∏∑‡πà‡∏≠ 20-day MA > 50-day MA
```

#### ‡∏Ç‡πâ‡∏≠ 4.2 (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
Merging ‡πÅ‡∏•‡∏∞ joining exercises:

```python
# ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏£‡∏≤‡∏á
customers = pd.DataFrame({
    'CustomerID': [1, 2, 3, 4, 5],
    'Name': ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve'],
    'City': ['Bangkok', 'Chiang Mai', 'Phuket', 'Bangkok', 'Pattaya'],
    'Age': [25, 30, 35, 28, 32]
})

orders = pd.DataFrame({
    'OrderID': [101, 102, 103, 104, 105, 106],
    'CustomerID': [1, 2, 1, 3, 2, 6],
    'Product': ['Laptop', 'Phone', 'Tablet', 'Watch', 'Laptop', 'Phone'],
    'Amount': [50000, 25000, 15000, 8000, 52000, 26000],
    'Order_Date': pd.date_range('2023-01-01', periods=6, freq='10D')
})

products = pd.DataFrame({
    'Product': ['Laptop', 'Phone', 'Tablet', 'Watch', 'Headphones'],
    'Category': ['Computer', 'Mobile', 'Computer', 'Wearable', 'Audio'],
    'Cost': [40000, 20000, 12000, 6000, 3000]
})

# TODO: Merging exercises
# 1. ‡∏£‡∏ß‡∏° customers ‡πÅ‡∏•‡∏∞ orders (‡πÅ‡∏™‡∏î‡∏á‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠)
# 2. ‡∏£‡∏ß‡∏° orders ‡πÅ‡∏•‡∏∞ products ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤ profit ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ order
# 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á comprehensive report ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≤‡∏°‡∏ï‡∏≤‡∏£‡∏≤‡∏á
# 4. ‡∏´‡∏≤‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏°‡∏∑‡∏≠‡∏á
# 5. ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏¢‡∏≠‡∏î‡∏Ç‡∏≤‡∏¢‡∏ï‡∏≤‡∏° category ‡πÅ‡∏•‡∏∞ customer demographics
```

### ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 5: Advanced Operations (20 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)

#### ‡∏Ç‡πâ‡∏≠ 5.1 (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ pivot tables ‡πÅ‡∏•‡∏∞ reshaping:

```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• survey
survey_data = pd.DataFrame({
    'RespondentID': range(1, 101),
    'Age_Group': np.random.choice(['18-25', '26-35', '36-45', '46-55', '55+'], 100),
    'Gender': np.random.choice(['Male', 'Female', 'Other'], 100),
    'Region': np.random.choice(['Bangkok', 'North', 'Northeast', 'Central', 'South'], 100),
    'Product_A_Rating': np.random.randint(1, 6, 100),
    'Product_B_Rating': np.random.randint(1, 6, 100),
    'Product_C_Rating': np.random.randint(1, 6, 100),
    'Overall_Satisfaction': np.random.randint(1, 6, 100)
})

# TODO: Pivot ‡πÅ‡∏•‡∏∞ reshape operations
# 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á pivot table ‡πÅ‡∏™‡∏î‡∏á average rating ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ product ‡∏ï‡∏≤‡∏° age group ‡πÅ‡∏•‡∏∞ gender
# 2. Melt data ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏õ‡∏•‡∏á product ratings ‡πÄ‡∏õ‡πá‡∏ô long format
# 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á cross-tabulation ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á region ‡πÅ‡∏•‡∏∞ age group
# 4. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì correlation ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á product ratings ‡πÅ‡∏•‡∏∞ overall satisfaction
# 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á summary report ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ñ‡∏∂‡∏á insights ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
```

#### ‡∏Ç‡πâ‡∏≠ 5.2 (10 ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
Performance optimization exercise:

```python
# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà
large_dataset = pd.DataFrame({
    'ID': range(1000000),
    'Category': np.random.choice(['A', 'B', 'C', 'D', 'E'], 1000000),
    'Value1': np.random.randn(1000000),
    'Value2': np.random.randint(1, 1000, 1000000),
    'Date': pd.date_range('2020-01-01', periods=1000000, freq='min')
})

# TODO: Optimization exercises
# 1. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö performance ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á iterrows(), apply(), ‡πÅ‡∏•‡∏∞ vectorization
# 2. Optimize memory usage ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô data types
# 3. ‡πÉ‡∏ä‡πâ categorical data type ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Category column
# 4. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö performance ‡∏Ç‡∏≠‡∏á groupby operations ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà
# 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà process ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û

def optimize_dataframe(df):
    """
    Optimize DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö memory ‡πÅ‡∏•‡∏∞ performance
    
    Returns:
    optimized DataFrame ‡πÅ‡∏•‡∏∞ report ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î memory
    """
    # TODO: implement optimization
    pass
```

